# Nate EDA ----
# Look at number of ratings to get a note published
notes_merged %>% group_by(current_status) %>% summarise(mean_ratings = mean(ratings, na.rm = TRUE))
# Nate EDA ----
# Look at number of ratings to get a note published
notes_merged %>% group_by(current_status) %>%
summarise(min(ratings))
# Nate EDA ----
# Look at number of ratings to get a note published
notes_merged %>% group_by(current_status) %>%
summarise(quantile(ratings,probs = 0.1))
# Nate EDA ----
# Look at number of ratings to get a note published
notes_merged %>% group_by(current_status) %>%
summarise(quantile(ratings,probs = 0.2))
# Nate EDA ----
# Look at number of ratings to get a note published
notes_merged %>% group_by(current_status) %>%
summarise(quantile(ratings,probs = 0.25))
# Nate EDA ----
# Look at number of ratings to get a note published
notes_merged %>% group_by(current_status) %>%
summarise(quantile(ratings,probs = 0.5))
# Nate EDA ----
# Look at number of ratings to get a note published
notes_merged %>% group_by(current_status) %>%
summarise(quantile(ratings,probs = 0.25))
# Extract published notes with low ratings
notes_merged %>% filter(ratings < 5 && current_status != "NEEDS_MORE_RATINIGS")
# Extract published notes with low ratings
notes_merged %>% filter(ratings < 5) %>% filter(current_status != "NEEDS_MORE_RATINIGS")
# Extract published notes with low ratings
notes_merged %>% filter(ratings < 3) %>% filter(current_status != "NEEDS_MORE_RATINIGS")
# Extract published notes with low ratings
notes_merged %>% filter(ratings < 2) %>% filter(current_status != "NEEDS_MORE_RATINIGS")
# Extract published notes with low ratings
notes_merged %>% filter(ratings < 1) %>% filter(current_status != "NEEDS_MORE_RATINIGS")
# Extract published notes with low ratings
notes_merged %>% filter(ratings < 1) %>%
filter(current_status != "NEEDS_MORE_RATINIGS") %>% View()
# Extract published notes with low ratings
notes_merged %>% filter(ratings < 1) %>%
filter(current_status != "NEEDS_MORE_RATINIGS") %>%
format(scientific = F) %>% View()
# Extract published notes with low ratings
notes_merged %>% filter(ratings < 1) %>%
filter(current_status != "NEEDS_MORE_RATINIGS") %>%
select(tweet_id) %>% pull() %>% format(scientific = F) %>% View()
# The note with most ratings
notes_merged %>% filter(ratings>6000) %>% arrange(ratings) %>%
select(tweet_id) %>%
pull() %>%
format(scientific = F)
# Extract published notes with low ratings
notes_merged %>% filter(ratings < 1) %>%
filter(current_status != "NEEDS_MORE_RATINIGS") %>%
select(tweet_id) %>% format(scientific = F) %>% View()
# Nate EDA ----
# Remove scientific notation
notes_merged$tweet_id <- notes_merged$tweet_id %>% format(scientific = F)
# Extract published notes with low ratings
notes_merged %>% filter(ratings < 1) %>%
filter(current_status != "NEEDS_MORE_RATINIGS") %>%
View()
notes_merged <- notes_merged %>% filter(ratings>0)
# Look at number of ratings to get a note published
notes_merged %>% group_by(current_status) %>%
summarise(quantile(ratings,probs = 0.25))
# Extract published notes with low ratings
notes_merged %>% filter(ratings < 1) %>%
filter(current_status != "NEEDS_MORE_RATINIGS") %>%
View()
# Extract published notes with low ratings
notes_merged %>% filter(ratings < 2) %>%
filter(current_status != "NEEDS_MORE_RATINIGS") %>%
View()
# Extract published notes with low ratings
notes_merged %>% filter(ratings < 2) %>%
filter(-(current_status = "NEEDS_MORE_RATINIGS")) %>%
View()
# Extract published notes with low ratings
notes_merged %>% filter(ratings < 2) %>%
select(-(current_status = "NEEDS_MORE_RATINIGS")) %>%
View()
# Extract published notes with low ratings
notes_merged %>% filter(ratings < 2) %>%
select(-(current_status = "NEEDS_MORE_RATINIGS")) %>%
View()
# Extract published notes with low ratings
notes_merged %>% filter(ratings < 2) %>%
select(-(current_status == "NEEDS_MORE_RATINIGS")) %>%
View()
# Extract published notes with low ratings
notes_merged %>% filter(ratings < 2) %>%
select((current_status =! "NEEDS_MORE_RATINIGS")) %>%
View()
# Extract published notes with low ratings
notes_merged %>% filter(ratings < 2) %>%
select((current_status != "NEEDS_MORE_RATINIGS")) %>%
View()
# Extract published notes with low ratings
notes_merged %>%
filter(ratings < 2, current_status != "NEEDS_MORE_RATINGS") %>% View()
# Extract published notes with low ratings
notes_merged %>%
filter(ratings < 2, current_status != "NEEDS_MORE_RATINGS") %>%
View()
# Extract published notes with low ratings
notes_merged %>%
filter(ratings < 6, current_status != "NEEDS_MORE_RATINGS") %>%
View()
# Extract published notes with low ratings
notes_merged %>%
filter(ratings < 5, current_status != "NEEDS_MORE_RATINGS") %>%
View()
# Extract published notes with low ratings
notes_merged %>%
filter(ratings < 4, current_status != "NEEDS_MORE_RATINGS") %>%
View()
# Extract published notes with low ratings
notes_merged %>%
filter(ratings < 3, current_status != "NEEDS_MORE_RATINGS") %>%
View()
# Extract published notes with low ratings
notes_merged %>%
filter(ratings < 6, current_status != "NEEDS_MORE_RATINGS") %>%
View()
# Extract published notes with low ratings
notes_merged %>%
filter(ratings < 6, current_status != "NEEDS_MORE_RATINGS") %>%
head())
# Extract published notes with low ratings
notes_merged %>%
filter(ratings < 6, current_status != "NEEDS_MORE_RATINGS") %>%
head()
# Extract published notes with low ratings
notes_merged %>%
filter(ratings < 6, current_status != "NEEDS_MORE_RATINGS", helpful_rate < 0.5) %>%
head()
# Extract published notes with low ratings
notes_merged %>%
filter(ratings < 6, current_status != "NEEDS_MORE_RATINGS", helpful_rate >= 0.5) %>%
head()
# Extract published notes with low ratings
notes_merged %>%
filter(ratings < 6, current_status != "NEEDS_MORE_RATINGS", helpful_rate >= 0.5) %>%
head(,10)
# Extract published notes with low ratings
notes_merged %>%
filter(ratings < 6, current_status != "NEEDS_MORE_RATINGS", helpful_rate >= 0.5) %>%
tai()
# Extract published notes with low ratings
notes_merged %>%
filter(ratings < 6, current_status != "NEEDS_MORE_RATINGS", helpful_rate >= 0.5) %>%
tail()
# Extract published notes with low ratings
notes_merged %>%
filter(ratings < 6, current_status != "NEEDS_MORE_RATINGS", helpful_rate >= 0.75) %>%
tail()
# Extract published notes with low ratings
notes_merged %>%
filter(ratings < 6, current_status != "NEEDS_MORE_RATINGS", helpful_rate >= 0.75) %>%
View()
# Extract published notes with low ratings
notes_merged %>%
filter(ratings < 6, current_status != "NEEDS_MORE_RATINGS", helpful_rate >= 0.75) %>%
head()
# Extract published notes with low ratings
notes_merged %>%
filter(ratings < 6, current_status != "NEEDS_MORE_RATINGS", helpful_rate >= 0.75) %>%
head()
# packages and data ----
library(pacman)
id_snippet <- notes_merged %>% select(tweet_id)
# packages and data ----
library(pacman)
p_load(tidyverse,
ggplot2,
corrplot)
id_snippet <- notes_merged %>% select(tweet_id)
View(id_snippet)
id_snippet <- notes_merged %>% select(tweet_id) %>% head(100)
View(id_snippet)
snippet_list <- paste0('"',id_snippet$tweet_id,'"', collapse = ",")
snippet_list <- paste0("[",snippet_listm"]")
snippet_list <- paste0("[",snippet_listm,"]")
snippet_list <- paste0("[",snippet_list,"]")
write(snippet_list, file = "tweet_ids.txt")
# Grab 100 ids to use in python
id_snippet <- notes_merged %>% select(tweet_id) %>% head(100)
View(id_snippet)
snippet_list <- paste0("[", paste(id_snippet$tweet_ids, collapse = ", "), "]")
snippet_list <- paste0("[", paste(id_snippet$tweet_id, collapse = ", "), "]")
write(snippet_list, file = "tweet_ids.txt")
snippet_list <- paste0("[", paste(id_snippet$tweet_id, collapse = ","), "]")
write(snippet_list, file = "tweet_ids.txt")
View(id_snippet)
# Grab 100 ids to use in python
id_snippet <- notes_merged %>% select(tweet_id) %>% head(50)
# packages and data ----
library(pacman)
p_load(tidyverse,
ggplot2,
corrplot)
# Grab 100 ids to use in python
id_snippet <- notes_merged %>% select(tweet_id) %>% head(50)
View(id_snippet)
# Grab 100 ids to use in python
id_snippet <- notes_merged %>% select(tweet_id) %>% tail(50)
View(id_snippet)
snippet_list <- paste0("[", paste(id_snippet$tweet_id, collapse = ","), "]")
write(snippet_list, file = "tweet_ids.txt")
# Grab 100 ids to use in python
id_snippet <- notes_merged %>% select(tweet_id) %>% head(100)
View(id_snippet)
snippet_list <- paste0("[", paste(id_snippet$tweet_id, collapse = ","), "]")
write(snippet_list, file = "tweet_ids.txt")
load("data/notes_merged.RData")
# Grab 100 ids to use in python
id_snippet <- notes_merged %>% select(tweet_id) %>% head(100)
# packages and data ----
library(pacman)
p_load(tidyverse,
ggplot2,
corrplot)
# Nate EDA ----
# Remove scientific notation/filter for tweets with ratings
notes_merged$tweet_id <- notes_merged$tweet_id %>% format(scientific = F)
notes_merged <- notes_merged %>% filter(ratings>0)
# Look at number of ratings to get a note published
notes_merged %>% group_by(current_status) %>%
summarise(quantile(ratings,probs = 0.25))
# Extract published notes with low ratings
notes_merged %>%
filter(ratings < 6, current_status != "NEEDS_MORE_RATINGS", helpful_rate >= 0.75) %>%
View()
# Grab 100 ids to use in python
id_snippet <- notes_merged %>% select(tweet_id) %>% head(100)
View(id_snippet)
snippet_list <- paste0("[", paste(id_snippet$tweet_id, collapse = ","), "]")
write(snippet_list, file = "tweet_ids.txt")
# packages
library(pacman)
p_load(tidyverse,
lubridate,
naniar,
janitor,
forcats)
rm(list = ls())
r15 <- read_tsv("data/raw_data/ratings-00011 (15).tsv") %>% clean_names()
View(r15)
# load data ----
# all the data was downloaded on December 3rd 2023
# notes
notes <- read_tsv("data/raw_data/notes-00000.tsv") %>% clean_names()
## status
status <- read_tsv("data/raw_data/noteStatusHistory-00000.tsv") %>% clean_names()
# Almost all the notes in notes are in status
sum(notes$note_id %in% status$note_id)
## Select the variables that will be used in the model from the notes dataset ----
notes_final <-
notes %>% select(
note_id,
tweet_id,
classification,
trustworthy_sources,
summary,
is_media_note,
created_at_millis
) %>%
mutate(created_at = as.POSIXct(created_at_millis / 1000, origin = "1970-01-01")) %>%
mutate(w_day = wday(created_at, label = T),
hour = as_factor(hour(created_at)),
note_length = nchar(summary)) %>%
select(-c(summary))
## select variables from ratings at the notes level ----
rates_summarise <-
bind_rows(r15) %>%
group_by(note_id) %>%
summarise(
ratings = n(),
agreement_rate = sum(agree)/n(),
helpful_rate = sum(helpfulness_level =="HELPFUL",na.rm = T)/n(),
not_helpful_rate = sum(helpfulness_level =="NOT_HELPFUL",na.rm = T)/n(),
somewhat_helpful_rate = sum(helpfulness_level =="SOMEWHAT_HELPFUL",na.rm = T)/n()
)
View(rates_summarise)
notes_merged <- left_join(notes_final, rates_summarise, by = join_by(note_id)) %>%
# some notes never received ratings, let's replace them with 0
replace_na(list(ratings = 0,
agreement_rate = 0,
helpful_rate = 0,
not_helpful_rate = 0,
somewhat_helpful_rate = 0))
notes_merged <-
left_join(x = notes_merged,
y = status %>%
# select onlye the non duplicated rows
filter(!(note_id %in% duplicated_notes_status)) %>%
# I only analyze the current status
select(note_id,current_status),
by = join_by(note_id))
# however they are all rated as "NEED MORE RATINGS"
duplicated_notes_status <-
status %>% group_by(note_id) %>%
summarise(n_notes = n()) %>%
filter(n_notes>1) %>%
pull(note_id) %>%
format(scientific = F)
notes_merged <-
left_join(x = notes_merged,
y = status %>%
# select onlye the non duplicated rows
filter(!(note_id %in% duplicated_notes_status)) %>%
# I only analyze the current status
select(note_id,current_status),
by = join_by(note_id))
View(notes_merged)
notes_merged <- filter(notes_merged,ratings>0)
View(notes_merged)
notes_2025 <- notes_merged %>% filter(format(datetime, "%Y") == "2025")
notes_2025 <- notes_merged %>% filter(format(created_at, "%Y") == "2025")
View(notes_2025)
# Ggplot visualisations
id_snippet <- notes_2025 %>% select(tweet_id) %>% head(100)
snippet_list <- paste0("[", paste(id_snippet$tweet_id, collapse = ","), "]")
write(snippet_list, file = "tweet_ids.txt")
# Ggplot visualisations
id_snippet <- notes_2025 %>% select(tweet_id) %>% tail(100)
write(snippet_list, file = "tweet_ids.txt")
tail(notes_2025)
View(notes_2025)
# Ggplot visualisations
id_snippet <- notes_2025 %>% select(tweet_id) %>% tail(100)
View(id_snippet)
snippet_list <- paste0("[", paste(id_snippet$tweet_id, collapse = ","), "]")
snippet_list <- paste0("[", paste(id_snippet$tweet_id, collapse = ","), "]")
# Ggplot visualisations
id_snippet <- notes_2025 %>% select(tweet_id) %>% head(100)
snippet_list <- paste0("[", paste(id_snippet$tweet_id, collapse = ","), "]")
# Ggplot visualisations
id_snippet <- notes_2025 %>% select(tweet_id) %>% tail(100)
snippet_list <- paste0("[", paste(id_snippet$tweet_id, collapse = ","), "]")
write(snippet_list, file = "tweet_ids.txt")
View(notes_2025)
# Ggplot visualisations
id_snippet <- notes_2025 %>% select(tweet_id)
# packages and data ----
library(pacman)
p_load(tidyverse,
ggplot2,
corrplot)
# Ggplot visualisations
id_snippet <- notes_2025 %>% select(tweet_id)
snippet_list <- paste0("[", paste(id_snippet$tweet_id, collapse = ","), "]")
write(snippet_list, file = "tweet_ids.txt")
View(id_snippet)
View(notes_merged)
library(swirl)
swirl()
View(notes_2025)
# Ggplot visualisations
id_snippet <- notes_2025 %>% select(tweet_id) %>% tail(100)
# packages and data ----
library(pacman)
p_load(tidyverse,
ggplot2,
corrplot)
# Ggplot visualisations
id_snippet <- notes_2025 %>% select(tweet_id) %>% tail(100)
View(id_snippet)
# Ggplot visualisations
id_snippet <- notes_2025 %>% select(tweet_id)
snippet_list <- paste0("[", paste(id_snippet$tweet_id, collapse = ","), "]")
write(snippet_list, file = "tweet_ids.txt")
# packages and data ----
library(pacman)
p_load(tidyverse,
ggplot2,
corrplot)
View(notes_2025)
filter(notes_2025 %>% unique(tweet_id))
filter(notes_2025,unique(tweet_id))
notes$tweet_id <- unique(notes_2025$tweet_id)
View(notes_merged)
# packages and data ----
library(pacman)
p_load(tidyverse,
ggplot2,
corrplot)
### Far more misleading ----
ggplot(notes_merged, aes(x = classification)) +
geom_bar() +
labs(title = "Distribution of Classifications")
### Far more needs more ratings ----
ggplot(notes_merged, aes(x = current_status)) +
geom_bar() +
labs(title = "Distribution of Current Status")
### Notes need high agreement to be published ----
notes_merged %>% filter(agreement_rate>0) %>%
ggplot(aes(x = agreement_rate)) +
geom_histogram(binwidth = 0.05) +
labs(title = "Distribution of Agreement Rate")
filter(sampled_data, ratings>1) %>% ggplot(aes(x=current_status, y = ratings))+
geom_boxplot()+
ylim(0,500)
sampled_data <- notes_merged[sample(nrow(notes_merged), 10000), ]
filter(sampled_data, ratings>1) %>% ggplot(aes(x=current_status, y = ratings))+
geom_boxplot()+
ylim(0,500)
filter(sampled_data, ratings>1) %>% ggplot(aes(x=current_status, y = ratings))+
geom_boxplot()+
ylim(0,500)
sampled_data <- notes_merged[sample(nrow(notes_merged), 10000), ]
filter(sampled_data, ratings>1) %>% ggplot(aes(x=current_status, y = ratings))+
geom_boxplot()+
ylim(0,500)
filter(sampled_data, ratings>1) %>% ggplot(aes(x=current_status, y = ratings))+
geom_boxplot()+
ylim(0,100)
sampled_data <- notes_merged[sample(nrow(notes_merged), 100000), ]
filter(sampled_data, ratings>1) %>% ggplot(aes(x=current_status, y = ratings))+
geom_boxplot()+
ylim(0,100)
filter(sampled_data, ratings>10) %>% ggplot(aes(x=current_status, y = ratings))+
geom_boxplot()+
ylim(0,100)
# Ggplot visualisations
id_snippet <- notes_merged %>% select(tweet_id) %>% filter(status = "NEEDS_MORE_RATINGS" && ratings > 10)
# Ggplot visualisations
id_snippet <- notes_merged %>% select(tweet_id) %>% filter(status == "NEEDS_MORE_RATINGS" && ratings > 10)
# Ggplot visualisations
id_snippet <- notes_merged %>% select(tweet_id) %>% filter(status == "NEEDS_MORE_RATINGS") %>% filter(ratings > 10)
# Ggplot visualisations
id_snippet <- notes_merged %>% select(tweet_id) %>% filter(current_status == "NEEDS_MORE_RATINGS") %>% filter(ratings > 10)
# Ggplot visualisations
id_snippet <- notes_merged %>% select(tweet_id)
id_snippet <- id_snippet %>% filter(current_status == "NEEDS_MORE_RATINGS") %>% filter(ratings > 10)
id_snippet <- id_snippet %>% filter(current_status = "NEEDS_MORE_RATINGS") %>% filter(ratings > 10)
# Ggplot visualisations
id_snippet <- notes_merged %>% filter(current_status == "NEEDS_MORE_RATINGS")
id_snippet <- id_snippet %>% filter(ratings > 10)
id_snippet <- id_snippet %>% select(tweet_id)
View(id_snippet)
id_snippet <- id_snippet %>% select(tweet_id) %>% format(scientific = F)
# Ggplot visualisations
id_snippet <- notes_merged %>% filter(current_status == "NEEDS_MORE_RATINGS")
id_snippet <- id_snippet %>% filter(ratings > 10)
id_snippet <- id_snippet %>% select(tweet_id) %>% format(scientific = F)
snippet_list <- paste0("[", paste(id_snippet$tweet_id, collapse = ","), "]")
# Ggplot visualisations
id_snippet <- notes_merged %>% filter(current_status == "NEEDS_MORE_RATINGS")
id_snippet <- id_snippet %>% filter(ratings > 10)
id_snippet <- id_snippet %>% select(tweet_id)
id_snippet <- id_snippet %>% format(scientific = F)
# Ggplot visualisations
id_snippet <- notes_merged %>% filter(current_status == "NEEDS_MORE_RATINGS")
id_snippet <- id_snippet %>% filter(ratings > 10)
id_snippet <- id_snippet %>% select(tweet_id)
snippet_list <- paste0("[", paste(id_snippet$tweet_id, collapse = ","), "]")
# Ggplot visualisations
id_snippet <- notes_merged %>% filter(current_status == "NEEDS_MORE_RATINGS")
id_snippet <- id_snippet %>% filter(ratings > 10)
id_snippet <- id_snippet %>% select(tweet_id)
View(id_snippet)
write(snippet_list, file = "tweet_ids.txt")
id_snippet <- id_snippet %>% unique()
# packages and data ----
library(pacman)
p_load(tidyverse,
ggplot2,
corrplot)
id_snippet <- id_snippet %>% unique()
snippet_list <- paste0("[", paste(id_snippet$tweet_id, collapse = ","), "]")
write(snippet_list, file = "tweet_ids.txt")
# packages
library(pacman)
p_load(tidyverse,
lubridate,
naniar,
janitor,
forcats)
# packages
library(pacman)
p_load(tidyverse,
lubridate,
naniar,
janitor,
forcats)
rm(list = ls())
# load data ----
# all the data was downloaded on December 3rd 2023
# notes
notes <- read_tsv("data/raw_data/notes-00000.tsv") %>% clean_names()
## status
status <- read_tsv("data/raw_data/noteStatusHistory-00000.tsv") %>% clean_names()
## ratings
r1 <- read_tsv("data/raw_data/ratings-00000 (1).tsv") %>% clean_names()
r2 <- read_tsv("data/raw_data/ratings-00007 (2).tsv") %>% clean_names()
r3 <- read_tsv("data/raw_data/ratings-00013 (3).tsv") %>% clean_names()
r4 <- read_tsv("data/raw_data/ratings-00012 (4).tsv") %>% clean_names()
r5 <- read_tsv("data/raw_data/ratings-00009 (5).tsv") %>% clean_names()
r6 <- read_tsv("data/raw_data/ratings-00001 (6).tsv") %>% clean_names()
r7 <- read_tsv("data/raw_data/ratings-00014 (7).tsv") %>% clean_names()
r8 <- read_tsv("data/raw_data/ratings-00002 (8).tsv") %>% clean_names()
r9 <- read_tsv("data/raw_data/ratings-00015 (9).tsv") %>% clean_names()
r10 <- read_tsv("data/raw_data/ratings-00004 (10).tsv") %>% clean_names()
r11 <- read_tsv("data/raw_data/ratings-00003 (11).tsv") %>% clean_names()
r12 <- read_tsv("data/raw_data/ratings-00005 (12).tsv") %>% clean_names()
r13 <- read_tsv("data/raw_data/ratings-00010 (13).tsv") %>% clean_names()
r14 <- read_tsv("data/raw_data/ratings-00006 (14).tsv") %>% clean_names()
r15 <- read_tsv("data/raw_data/ratings-00011 (15).tsv") %>% clean_names()
