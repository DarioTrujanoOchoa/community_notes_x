notes_final <-
notes %>% select(
note_id,
tweet_id,
classification,
trustworthy_sources,
summary,
is_media_note,
created_at_millis
) %>%
mutate(created_at = as.POSIXct(created_at_millis, origin="1970-01-01")) %>%
mutate(w_day = wday(created_at, label = T),
hour = as_factor(hour(created_at)),
note_length = nchar(summary)) %>%
select(-c(created_at_millis,
summary))
## Select the variables that will be used in the model from the notes dataset ----
notes_final <-
notes %>% select(
note_id,
tweet_id,
classification,
trustworthy_sources,
summary,
is_media_note,
created_at_millis
) %>%
mutate(created_at = as.POSIXct(created_at_millis, origin="1970-01-01")) %>%
mutate(w_day = wday(created_at, label = T),
hour = as_factor(hour(created_at)),
note_length = nchar(summary)) %>%
select(-c(created_at_millis,
summary))
names(notes_final)
## Select the variables that will be used in the model from the notes dataset ----
notes_final <-
notes %>% select(
note_id,
tweet_id,
classification,
trustworthy_sources,
summary,
is_media_note,
created_at_millis
) %>%
mutate(created_at = as.POSIXct(created_at_millis, origin="1970-01-01")) %>%
mutate(w_day = wday(created_at, label = T),
hour = as_factor(hour(created_at)),
note_length = nchar(summary)) %>%
select(-c(created_at_millis,
summary))
## select variables from ratings at the notes level ----
rates_summarise <-
bind_rows(r0,
r1,
r2,
r3) %>%
group_by(note_id) %>%
summarise(
ratings = n(),
agreement_rate = sum(agree)/n(),
helpful_rate = sum(helpfulness_level =="HELPFUL",na.rm = T)/n(),
not_helpful_rate = sum(helpfulness_level =="NOT_HELPFUL",na.rm = T)/n(),
somewhat_helpful_rate = sum(helpfulness_level =="SOMEWHAT_HELPFUL",na.rm = T)/n()
)
## select variables from ratings at the notes level ----
rates_summarise <-
bind_rows(r0,
#r1,
r2,
r3) %>%
group_by(note_id) %>%
summarise(
ratings = n(),
agreement_rate = sum(agree)/n(),
helpful_rate = sum(helpfulness_level =="HELPFUL",na.rm = T)/n(),
not_helpful_rate = sum(helpfulness_level =="NOT_HELPFUL",na.rm = T)/n(),
somewhat_helpful_rate = sum(helpfulness_level =="SOMEWHAT_HELPFUL",na.rm = T)/n()
)
# merge data ----
# Notes in both data sets are not exactly the same
# 9.3% of the notes never received ratings
1 - mean(notes_final$note_id %in% rates_summarise$note_id)
notes_merged <- left_join(notes_final, rates_summarise, by = join_by(note_id)) %>%
# some notes never received ratings, let's replace them with 0
replace_na(list(ratings = 0,
agreement_rate = 0,
helpful_rate = 0,
not_helpful_rate = 0,
somewhat_helpful_rate = 0))
notes_merged <-
left_join(x = notes_merged,
y = status %>%
# select onlye the non duplicated rows
filter(!(note_id %in% duplicated_notes_status)) %>%
# I only analyze the current status
select(note_id,current_status),
by = join_by(note_id))
notes_merged
names(notes_merged)
# however they are all rated as "NEED MORE RATINGS"
duplicated_notes_status <-
status %>% group_by(note_id) %>%
summarise(n_notes = n()) %>%
filter(n_notes>1) %>%
pull(note_id) %>%
format(scientific = F)
notes_merged <- left_join(notes_final, rates_summarise, by = join_by(note_id)) %>%
# some notes never received ratings, let's replace them with 0
replace_na(list(ratings = 0,
agreement_rate = 0,
helpful_rate = 0,
not_helpful_rate = 0,
somewhat_helpful_rate = 0))
notes_merged <-
left_join(x = notes_merged,
y = status %>%
# select onlye the non duplicated rows
filter(!(note_id %in% duplicated_notes_status)) %>%
# I only analyze the current status
select(note_id,current_status),
by = join_by(note_id))
load("data/notes_merged.RData")
# missing data ----
vis_miss(slice_sample(notes_merged,prop = 0.1))
# there are 3 rows with missing values
missing_cell <- which(is.na(notes_merged), arr.ind = TRUE)
notes_merged[missing_cell[,1],]
# These are the tweet ids
notes_merged[missing_cell[,1],] %>% select(tweet_id) %>% pull() %>% format(scientific = F) %>% unique()
# I remove the missing values, given the content and the number of missing values this shouldn't be an issue
notes_merged <- notes_merged %>% drop_na()
# Analyzing the outcome variable ----
summary(notes_merged$ratings)
# 99% of the notes have less than 453 ratings
q_99 <- quantile(notes_merged$ratings,probs = 0.99)
notes_merged %>%
filter(ratings < q_99) %>%
ggplot() +
geom_histogram(aes(x= ratings)) +
labs(
title = "Histogram of the number of Ratings on each Note",
subtitle = "Percentile 99 of the Ratings",
x="Number of Ratings"
) +
theme_bw()
notes_merged %>%
filter(ratings >= q_99) %>%
ggplot() +
geom_histogram(aes(x= ratings)) +
labs(
title = "Histogram of the number of Ratings on each Note",
subtitle = "1% of Notes with more Ratings",
x="Number of Ratings"
) +
theme_bw()
# The note with most ratings
notes_merged %>% filter(ratings>6000) %>% arrange(ratings) %>%
select(tweet_id) %>%
pull() %>%
format(scientific = F)
# Correlations ----
# Correlation matrix
notes_cor <- cor(notes_merged %>%
select(-ends_with("id")) %>%
select_if(is.numeric))
# Visualization of correlation matrix
notes_corrplot <- corrplot.mixed(notes_cor,
lower = 'shade', upper = 'pie', order = 'hclust',
addCoef.col = 1, number.cex = 0.7,
tl.pos = "lt"
)
p_load(tidyverse,
ggplot2,
corrplot)
# Correlations ----
# Correlation matrix
notes_cor <- cor(notes_merged %>%
select(-ends_with("id")) %>%
select_if(is.numeric))
# Visualization of correlation matrix
notes_corrplot <- corrplot.mixed(notes_cor,
lower = 'shade', upper = 'pie', order = 'hclust',
addCoef.col = 1, number.cex = 0.7,
tl.pos = "lt"
)
notes_merged %>%
filter(ratings > 1, ratings < 2000) %>%
ggplot() +
geom_boxplot(aes(x=current_status, y = ratings))
notes_merged %>% group_by(current_status) %>%
summarise(mean(ratings), median(ratings),
quantile(ratings,probs = 0.1),
quantile(ratings,probs = 0.9)
)
table(notes_merged$classification, notes_merged$current_status)
# Analyzing the outcome variable ----
summary(notes_merged$ratings)
# 99% of the notes have less than 453 ratings
q_99 <- quantile(notes_merged$ratings,probs = 0.99)
notes_merged %>%
filter(ratings < q_99) %>%
ggplot() +
geom_histogram(aes(x= ratings)) +
labs(
title = "Histogram of the number of Ratings on each Note",
subtitle = "Percentile 99 of the Ratings",
x="Number of Ratings"
) +
theme_bw()
notes_merged %>%
filter(ratings >= q_99) %>%
ggplot() +
geom_histogram(aes(x= ratings)) +
labs(
title = "Histogram of the number of Ratings on each Note",
subtitle = "1% of Notes with more Ratings",
x="Number of Ratings"
) +
theme_bw()
# The note with most ratings
notes_merged %>% filter(ratings>6000) %>% arrange(ratings) %>%
select(tweet_id) %>%
pull() %>%
format(scientific = F)
notes_merged %>%
filter(ratings > 1, ratings < 2000) %>%
ggplot() +
geom_boxplot(aes(x=current_status, y = ratings))
notes_merged %>% group_by(current_status) %>%
summarise(mean(ratings), median(ratings),
quantile(ratings,probs = 0.1),
quantile(ratings,probs = 0.9)
)
table(notes_merged$classification, notes_merged$current_status)
knitr::opts_chunk$set(echo = TRUE)
notes_merged %>% group_by(classification) %>%
summarise(mean(ratings), median(ratings),
quantile(ratings,probs = 0.1),
quantile(ratings,probs = 0.9)
)
## Polynomial Regression ----
read_rds(poly_tuned, file = "data/tuned_models/poly.rds")
library(pacman)
p_load(tidyverse,
tidymodels,
recipes,
kknn,
yardstick,
tune,
ggplot2,
ggthemes,
rsample,
parsnip,
workflows,
glmnet,
ranger
)
## Polynomial Regression ----
read_rds(poly_tuned, file = "data/tuned_models/poly.rds")
## Polynomial Regression ----
read_rds(file = "data/tuned_models/poly.rds")
# Best model ----
show_best(poly_tuned, metric = 'rmse')
rm(list = ls())
library(pacman)
p_load(tidyverse,
tidymodels,
recipes,
kknn,
yardstick,
tune,
ggplot2,
ggthemes,
rsample,
parsnip,
workflows,
glmnet,
ranger
)
set.seed(1984)
# Load data ----
load("data/notes_merged.RData")
notes_merged <- notes_merged %>%
filter(created_at > "2022-11-25 15:30:30 UTC") %>%
slice_sample(prop = 0.05)
summary(notes_merged)
## Polynomial Regression ----
read_rds(file = "data/tuned_models/poly.rds")
## Polynomial Regression ----
read_rds(file = "data/tuned_models/poly.rds")
## Polynomial Regression ----
poly_tuned <- read_rds(file = "data/tuned_models/poly.rds")
# Best model ----
show_best(poly_tuned, metric = 'rmse')
# Best model ----
show_best(poly_tuned, metric = 'rmse', n=1)
best_train <- select_best(poly_tuned, metric = 'rmse')
## Fit to training data ----
final_workflow_train <- finalize_workflow(poly_wf, best_train)
# Recipe ----
rec_reg <- recipe(ratings ~  .,
data = train_notes) %>%
step_rm(note_id, tweet_id,
created_at, current_status) %>%
step_dummy(w_day, hour, classification) %>%
step_zv(all_predictors()) %>%
step_normalize(all_numeric_predictors())
notes_merged <- notes_merged %>%
filter(created_at > "2022-11-25 15:30:30 UTC") %>%
slice_sample(prop = 0.05)
summary(notes_merged)
# Split data and cross validation ----
training_percentage <- 0.75
split_notes <- initial_split(notes_merged,
prop = training_percentage,
strata = ratings)
train_notes <- training(split_notes)
test_notes <- testing(split_notes)
v_folds <- 10
notes_folds <- vfold_cv(train_notes, v = v_folds, strata = "ratings")
# Recipe ----
rec_reg <- recipe(ratings ~  .,
data = train_notes) %>%
step_rm(note_id, tweet_id,
created_at, current_status) %>%
step_dummy(w_day, hour, classification) %>%
step_zv(all_predictors()) %>%
step_normalize(all_numeric_predictors())
# Models ----
##linear model ----
linear_reg <- linear_reg() %>%
set_mode("regression") %>%
set_engine("lm")
# Polinomial Regression ----
poly_rec <- rec_reg %>%
step_poly(note_length, helpful_rate, not_helpful_rate,
degree = tune())
poly_spec <- linear_reg() %>%
set_mode("regression") %>%
set_engine("lm")
# KNN model
knn_mod <- nearest_neighbor(neighbors = tune()) %>%
set_mode("regression") %>%
set_engine("kknn")
## Elastic net ----
# Tuning penalty and mixture
en_mod <- linear_reg(penalty = tune(),
mixture = tune()) %>%
set_mode("regression") %>%
set_engine("glmnet")
## Random forest ----
# Tuning mtry (number of predictors), trees, and min_n (number of minimum values in each node)
rf_mod <- rand_forest(mtry = tune(),
trees = tune(),
min_n = tune()) %>%
set_engine("ranger", importance = "impurity") %>%
set_mode("regression")
# Workflow ----
## Linear ----
lm_wkflow <- workflow() %>%
# add model
add_model(linear_reg) %>%
# add receipe
add_recipe(rec_reg)
## POLYNOMIAL REGRESSION ----
poly_wf <- workflow() %>%
add_model(poly_spec) %>%
add_recipe(poly_rec)
## KNN ----
knn_wkflow <- workflow() %>%
# add model
add_model(knn_mod) %>%
# add receipe
add_recipe(rec_reg)
## EN ----
en_wkflow <- workflow() %>%
# add model
add_model(en_mod) %>%
# add receipe
add_recipe(rec_reg)
## RF ----
rf_wkflow <- workflow() %>%
# add model
add_model(rf_mod) %>%
# add receipe
add_recipe(rec_reg)
## POLYNOMIAL REGRESSION ----
degree_grid <- grid_regular(degree(range = c(1,5)), levels = 5)
## KNN ----
knn_grid <- grid_regular(neighbors(range = c(1,15)),
levels = 5)
## EN ----
en_grid <- grid_regular(penalty(range = c(-5, 5)),
mixture(range = c(0,1)),
levels = 10)
## RF ----
rf_grid <- grid_regular(mtry(range = c(1, 12)),
trees(range = c(20,60)),
min_n(range = c(5,20)),
levels = 8)
# Best model ----
show_best(poly_tuned, metric = 'rmse', n=1)
best_train <- select_best(poly_tuned, metric = 'rmse')
## Fit to training data ----
final_workflow_train <- finalize_workflow(poly_wf, best_train)
final_fit_train <- fit(final_workflow, data = notes_train)
final_fit_train <- fit(final_workflow_train, data = notes_train)
final_fit_train <- fit(final_workflow_train, data = train_notes)
final_fit_train
# Creating the predicted vs. actual value tibble
notes_tibble <- predict(final_fit_train, new_data = test_notes %>% select(-ratings))
notes_tibble <- bind_cols(notes_tibble, test_notes %>% select(ratings))
# Creating plot of predicted values vs. actual values
notes_tibble %>%
ggplot(aes(x = .pred, y = ratings)) +
geom_point(alpha = 0.4) +
geom_abline(lty = 2) +
theme_grey() +
coord_obs_pred() +
labs(title = "Predicted Values vs. Actual Values")
# Let's focus on the notes with not that many ratings
notes_tibble %>%
ggplot(aes(x = .pred, y = ratings)) +
geom_point(alpha = 0.4) +
geom_abline(lty = 2) +
xlim(0, 50) +
ylim(0, 50) +
theme_grey() +
coord_obs_pred() +
labs(title = "Predicted Values vs. Actual Values")
# Creating plot of predicted values vs. actual values
notes_tibble %>%
ggplot(aes(x = .pred, y = ratings)) +
geom_point(alpha = 0.4) +
geom_abline(lty = 2) +
theme_grey() +
coord_obs_pred() +
labs(title = "Predicted Values vs. Actual Values")
notes_tibble
# Let's focus on the notes with not that many ratings
notes_tibble %>%
filter(.pred < 50,
ratings < 50) %>%
ggplot(aes(x = .pred, y = ratings)) +
geom_point(alpha = 0.4) +
geom_abline(lty = 2) +
# xlim(0, 50) +
# ylim(0, 50) +
theme_grey() +
coord_obs_pred() +
labs(title = "Predicted Values vs. Actual Values")
# Let's focus on the notes with not that many ratings
notes_tibble %>%
filter(.pred < 50,
ratings < 50) %>%
ggplot(aes(x = .pred, y = ratings)) +
geom_point(alpha = 0.4) +
geom_abline(lty = 2) +
# xlim(0, 50) +
# ylim(0, 50) +
theme_grey() +
coord_obs_pred() +
labs(title = "Predicted Values vs. Actual Values",
x = "Model Prediction")
# Creating plot of predicted values vs. actual values
notes_tibble %>%
ggplot(aes(x = .pred, y = ratings)) +
geom_point(alpha = 0.4) +
geom_abline(lty = 2) +
theme_grey() +
coord_obs_pred() +
labs(title = "Predicted Values vs. Actual Values",
x = "Model Prediction")
# Let's focus on the notes with not that many ratings
notes_tibble %>%
filter(.pred < 50,
ratings < 50) %>%
ggplot(aes(x = .pred, y = ratings)) +
geom_point(alpha = 0.4) +
geom_abline(lty = 2) +
# xlim(0, 50) +
# ylim(0, 50) +
theme_grey() +
coord_obs_pred() +
labs(title = "Predicted Values vs. Actual Values",
x = "Model Prediction")
# Using the training fit to create the VIP because the model was not actually fit to the testing data
final_fit_train %>%
extract_fit_engine() %>%
vip(aesthetics = list(fill = "red3", color = "blue3"))
?vip
p_load(tidyverse,
tidymodels,
recipes,
kknn,
yardstick,
tune,
ggplot2,
ggthemes,
rsample,
parsnip,
workflows,
glmnet,
ranger,
vip
)
## VIP ----
# Using the training fit to create the VIP because the model was not actually fit to the testing data
final_fit_train %>%
extract_fit_engine() %>%
vip(aesthetics = list(fill = "red3", color = "blue3"))
