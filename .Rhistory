labs(title = "Predicted Values vs. Actual Values")
notes_tibble
# Let's focus on the notes with not that many ratings
notes_tibble %>%
filter(.pred < 50,
ratings < 50) %>%
ggplot(aes(x = .pred, y = ratings)) +
geom_point(alpha = 0.4) +
geom_abline(lty = 2) +
# xlim(0, 50) +
# ylim(0, 50) +
theme_grey() +
coord_obs_pred() +
labs(title = "Predicted Values vs. Actual Values")
# Let's focus on the notes with not that many ratings
notes_tibble %>%
filter(.pred < 50,
ratings < 50) %>%
ggplot(aes(x = .pred, y = ratings)) +
geom_point(alpha = 0.4) +
geom_abline(lty = 2) +
# xlim(0, 50) +
# ylim(0, 50) +
theme_grey() +
coord_obs_pred() +
labs(title = "Predicted Values vs. Actual Values",
x = "Model Prediction")
# Creating plot of predicted values vs. actual values
notes_tibble %>%
ggplot(aes(x = .pred, y = ratings)) +
geom_point(alpha = 0.4) +
geom_abline(lty = 2) +
theme_grey() +
coord_obs_pred() +
labs(title = "Predicted Values vs. Actual Values",
x = "Model Prediction")
# Let's focus on the notes with not that many ratings
notes_tibble %>%
filter(.pred < 50,
ratings < 50) %>%
ggplot(aes(x = .pred, y = ratings)) +
geom_point(alpha = 0.4) +
geom_abline(lty = 2) +
# xlim(0, 50) +
# ylim(0, 50) +
theme_grey() +
coord_obs_pred() +
labs(title = "Predicted Values vs. Actual Values",
x = "Model Prediction")
# Using the training fit to create the VIP because the model was not actually fit to the testing data
final_fit_train %>%
extract_fit_engine() %>%
vip(aesthetics = list(fill = "red3", color = "blue3"))
?vip
p_load(tidyverse,
tidymodels,
recipes,
kknn,
yardstick,
tune,
ggplot2,
ggthemes,
rsample,
parsnip,
workflows,
glmnet,
ranger,
vip
)
## VIP ----
# Using the training fit to create the VIP because the model was not actually fit to the testing data
final_fit_train %>%
extract_fit_engine() %>%
vip(aesthetics = list(fill = "red3", color = "blue3"))
data <- read_tsv("notes-00000 (1).tsv")
library(tidyverse)
data <- read_tsv("notes-00000 (1).tsv")
View(data)
head(data)
data$tweetId
forcats)
p_load(tidyverse,
lubridate,
naniar,
janitor,
forcats)
# load data ----
# all the data was downloaded on December 3rd 2023
# notes
notes <- read_tsv("data/notes-00000.tsv") %>% clean_names()
# packages
library(pacman)
p_load(tidyverse,
lubridate,
naniar,
janitor,
forcats)
# load data ----
# all the data was downloaded on December 3rd 2023
# notes
notes <- read_tsv("data/notes-00000.tsv") %>% clean_names()
## status
status <- read_tsv("data/noteStatusHistory-00000.tsv") %>% clean_names()
## ratings
r0 <- read_tsv("data/ratings-00000.tsv") %>% clean_names()
r1 <- read_tsv("data/ratings-00001.tsv") %>% clean_names()
r2 <- read_tsv("data/ratings-00002.tsv") %>% clean_names()
r3 <- read_tsv("data/ratings-00003.tsv") %>% clean_names()
# load data ----
# all the data was downloaded on December 3rd 2023
# notes
notes <- read_tsv("data/notes-00000.tsv") %>% clean_names()
# load data ----
# all the data was downloaded on December 3rd 2023
# notes
notes <- read_tsv("notes-00000 (1).tsv") %>% clean_names()
## status
status <- read_tsv("data/noteStatusHistory-00000.tsv") %>% clean_names()
# Almost all the notes in notes are in status
# only 20 notes are not there
sum(notes$note_id %in% status$note_id)
# packages and data ----
library(pacman)
p_load(tidyverse,
ggplot2,
corrplot)
# packages
library(pacman)
p_load(tidyverse,
lubridate,
naniar,
janitor,
forcats)
rm(list = ls())
# load data ----
# all the data was downloaded on December 3rd 2023
# notes
notes <- read_tsv("data/notes-00000.tsv") %>% clean_names()
# packages and data ----
library(pacman)
p_load(tidyverse,
ggplot2,
corrplot)
load("data/notes_merged.RData")
View(notes_merged)
group_by(notes_merged, current_status) %>% summarise()
group_by(notes_merged, current_status) %>% mean(ratings)
group_by(notes_merged, current_status) %>% mean(notes_merged$ratings)
group_by(notes_merged, current_status) %>% summarise(notes_merged$ratings)
group_by(notes_merged, current_status) %>% mean(notes_merged$ratings)
mean(notes_merged$ratings)
mean(group_by(notes_merged,current_status)$ratings)
group_by(notes_merged, current_status)
group_by(notes_merged, current_status) %>% tbl()
group_by(notes_merged, current_status) %>% notes_merged$ratings
group_by(notes_merged, current_status) %>% summarise(ratings)
otes_merged %>%
group_by(current_status) %>%
summarise(mean_ratings = mean(ratings, na.rm = TRUE))
notes_merged %>%
group_by(current_status) %>%
summarise(mean_ratings = mean(ratings, na.rm = TRUE))
# Nate EDA ----
# Look at number of ratings to get a note published
notes_merged %>% group_by(current_status) %>% summarise(mean_ratings = mean(ratings, na.rm = TRUE))
mean(notes_merged$agreement_rate)
notes_merged %>%
filter(ratings > 1, ratings < 2000) %>%
ggplot() +
geom_boxplot(aes(x=current_status, y = ratings))
notes_merged %>% group_by(current_status) %>%
summarise(mean(ratings), median(ratings),
quantile(ratings,probs = 0.1),
quantile(ratings,probs = 0.9)
)
table(notes_merged$classification, notes_merged$current_status)
# Visualization of correlation matrix
notes_corrplot <- corrplot.mixed(notes_cor,
lower = 'shade', upper = 'pie', order = 'hclust',
addCoef.col = 1, number.cex = 0.7,
tl.pos = "lt"
)
# missing data ----
# there are 3 rows with missing values
missing_cell <- which(is.na(notes_merged), arr.ind = TRUE)
notes_merged[missing_cell[,1],]
# These are the tweet ids
tweet_ids <- notes_merged[missing_cell[,1],] %>% select(tweet_id) %>% pull() %>% format(scientific = F) %>% unique()
View(missing_cell)
head(tweet_ids)
View(filter(notes_merged,tweet_id = "1370126844251435008"))
filter(notes_merged,tweet_id = "1370126844251435008") %>% View()
filter(notes_merged,tweet_id == "1370126844251435008") %>% View()
# These are the tweet ids
tweet_ids_missing <- notes_merged[missing_cell[,1],] %>% select(tweet_id) %>% pull() %>% format(scientific = F) %>% unique()
# packages and data ----
library(pacman)
rm(list=ls())
# packages and data ----
library(pacman)
p_load(tidyverse,
ggplot2,
corrplot)
rm(list=ls())
load("data/notes_merged.RData")
# missing data ----
# there are 3 rows with missing values
missing_cell <- which(is.na(notes_merged), arr.ind = TRUE)
View(missing_cell)
View(notes_merged)
unique(missing_cell$col)
unique(missing_cell)
unique(missing_cell[2])
unique(,missing_cell)
unique(missing_cell,2)
unique(missing_cell,col)
notes_merged[missing_cell[,1],]
# These are the tweet ids
tweet_ids_missing <- notes_merged[missing_cell[,1],] %>% select(tweet_id) %>% pull() %>% format(scientific = F) %>% unique()
# I remove the missing values, given the content and the number of missing values this shouldn't be an issue
notes_merged <- notes_merged %>% drop_na()
# Analyzing the outcome variable ----
summary(notes_merged$ratings)
# 99% of the notes have less than 453 ratings
q_99 <- quantile(notes_merged$ratings,probs = 0.99)
notes_merged %>%
filter(ratings < q_99) %>%
ggplot() +
geom_histogram(aes(x= ratings)) +
labs(
title = "Histogram of the number of Ratings on each Note",
subtitle = "Percentile 99 of the Ratings",
x="Number of Ratings"
) +
theme_bw()
notes_merged %>%
filter(ratings >= q_99) %>%
ggplot() +
geom_histogram(aes(x= ratings)) +
labs(
title = "Histogram of the number of Ratings on each Note",
subtitle = "1% of Notes with more Ratings",
x="Number of Ratings"
) +
theme_bw()
# The note with most ratings
notes_merged %>% filter(ratings>6000) %>% arrange(ratings) %>%
select(tweet_id) %>%
pull() %>%
format(scientific = F)
# Correlations ----
# Correlation matrix
notes_cor <- cor(notes_merged %>%
select(-ends_with("id")) %>%
select_if(is.numeric))
# Visualization of correlation matrix
notes_corrplot <- corrplot.mixed(notes_cor,
lower = 'shade', upper = 'pie', order = 'hclust',
addCoef.col = 1, number.cex = 0.7,
tl.pos = "lt"
)
notes_merged %>%
filter(ratings > 1, ratings < 2000) %>%
ggplot() +
geom_boxplot(aes(x=current_status, y = ratings))
notes_merged %>% group_by(current_status) %>%
summarise(mean(ratings), median(ratings),
quantile(ratings,probs = 0.1),
quantile(ratings,probs = 0.9)
)
table(notes_merged$classification, notes_merged$current_status)
# Nate EDA ----
# Look at number of ratings to get a note published
notes_merged %>% group_by(current_status) %>% summarise(mean_ratings = mean(ratings, na.rm = TRUE))
# Nate EDA ----
# Look at number of ratings to get a note published
notes_merged %>% group_by(current_status) %>%
summarise(min(ratings))
# Nate EDA ----
# Look at number of ratings to get a note published
notes_merged %>% group_by(current_status) %>%
summarise(quantile(ratings,probs = 0.1))
# Nate EDA ----
# Look at number of ratings to get a note published
notes_merged %>% group_by(current_status) %>%
summarise(quantile(ratings,probs = 0.2))
# Nate EDA ----
# Look at number of ratings to get a note published
notes_merged %>% group_by(current_status) %>%
summarise(quantile(ratings,probs = 0.25))
# Nate EDA ----
# Look at number of ratings to get a note published
notes_merged %>% group_by(current_status) %>%
summarise(quantile(ratings,probs = 0.5))
# Nate EDA ----
# Look at number of ratings to get a note published
notes_merged %>% group_by(current_status) %>%
summarise(quantile(ratings,probs = 0.25))
# Extract published notes with low ratings
notes_merged %>% filter(ratings < 5 && current_status != "NEEDS_MORE_RATINIGS")
# Extract published notes with low ratings
notes_merged %>% filter(ratings < 5) %>% filter(current_status != "NEEDS_MORE_RATINIGS")
# Extract published notes with low ratings
notes_merged %>% filter(ratings < 3) %>% filter(current_status != "NEEDS_MORE_RATINIGS")
# Extract published notes with low ratings
notes_merged %>% filter(ratings < 2) %>% filter(current_status != "NEEDS_MORE_RATINIGS")
# Extract published notes with low ratings
notes_merged %>% filter(ratings < 1) %>% filter(current_status != "NEEDS_MORE_RATINIGS")
# Extract published notes with low ratings
notes_merged %>% filter(ratings < 1) %>%
filter(current_status != "NEEDS_MORE_RATINIGS") %>% View()
# Extract published notes with low ratings
notes_merged %>% filter(ratings < 1) %>%
filter(current_status != "NEEDS_MORE_RATINIGS") %>%
format(scientific = F) %>% View()
# Extract published notes with low ratings
notes_merged %>% filter(ratings < 1) %>%
filter(current_status != "NEEDS_MORE_RATINIGS") %>%
select(tweet_id) %>% pull() %>% format(scientific = F) %>% View()
# The note with most ratings
notes_merged %>% filter(ratings>6000) %>% arrange(ratings) %>%
select(tweet_id) %>%
pull() %>%
format(scientific = F)
# Extract published notes with low ratings
notes_merged %>% filter(ratings < 1) %>%
filter(current_status != "NEEDS_MORE_RATINIGS") %>%
select(tweet_id) %>% format(scientific = F) %>% View()
# Nate EDA ----
# Remove scientific notation
notes_merged$tweet_id <- notes_merged$tweet_id %>% format(scientific = F)
# Extract published notes with low ratings
notes_merged %>% filter(ratings < 1) %>%
filter(current_status != "NEEDS_MORE_RATINIGS") %>%
View()
notes_merged <- notes_merged %>% filter(ratings>0)
# Look at number of ratings to get a note published
notes_merged %>% group_by(current_status) %>%
summarise(quantile(ratings,probs = 0.25))
# Extract published notes with low ratings
notes_merged %>% filter(ratings < 1) %>%
filter(current_status != "NEEDS_MORE_RATINIGS") %>%
View()
# Extract published notes with low ratings
notes_merged %>% filter(ratings < 2) %>%
filter(current_status != "NEEDS_MORE_RATINIGS") %>%
View()
# Extract published notes with low ratings
notes_merged %>% filter(ratings < 2) %>%
filter(-(current_status = "NEEDS_MORE_RATINIGS")) %>%
View()
# Extract published notes with low ratings
notes_merged %>% filter(ratings < 2) %>%
select(-(current_status = "NEEDS_MORE_RATINIGS")) %>%
View()
# Extract published notes with low ratings
notes_merged %>% filter(ratings < 2) %>%
select(-(current_status = "NEEDS_MORE_RATINIGS")) %>%
View()
# Extract published notes with low ratings
notes_merged %>% filter(ratings < 2) %>%
select(-(current_status == "NEEDS_MORE_RATINIGS")) %>%
View()
# Extract published notes with low ratings
notes_merged %>% filter(ratings < 2) %>%
select((current_status =! "NEEDS_MORE_RATINIGS")) %>%
View()
# Extract published notes with low ratings
notes_merged %>% filter(ratings < 2) %>%
select((current_status != "NEEDS_MORE_RATINIGS")) %>%
View()
# Extract published notes with low ratings
notes_merged %>%
filter(ratings < 2, current_status != "NEEDS_MORE_RATINGS") %>% View()
# Extract published notes with low ratings
notes_merged %>%
filter(ratings < 2, current_status != "NEEDS_MORE_RATINGS") %>%
View()
# Extract published notes with low ratings
notes_merged %>%
filter(ratings < 6, current_status != "NEEDS_MORE_RATINGS") %>%
View()
# Extract published notes with low ratings
notes_merged %>%
filter(ratings < 5, current_status != "NEEDS_MORE_RATINGS") %>%
View()
# Extract published notes with low ratings
notes_merged %>%
filter(ratings < 4, current_status != "NEEDS_MORE_RATINGS") %>%
View()
# Extract published notes with low ratings
notes_merged %>%
filter(ratings < 3, current_status != "NEEDS_MORE_RATINGS") %>%
View()
# Extract published notes with low ratings
notes_merged %>%
filter(ratings < 6, current_status != "NEEDS_MORE_RATINGS") %>%
View()
# Extract published notes with low ratings
notes_merged %>%
filter(ratings < 6, current_status != "NEEDS_MORE_RATINGS") %>%
head())
# Extract published notes with low ratings
notes_merged %>%
filter(ratings < 6, current_status != "NEEDS_MORE_RATINGS") %>%
head()
# Extract published notes with low ratings
notes_merged %>%
filter(ratings < 6, current_status != "NEEDS_MORE_RATINGS", helpful_rate < 0.5) %>%
head()
# Extract published notes with low ratings
notes_merged %>%
filter(ratings < 6, current_status != "NEEDS_MORE_RATINGS", helpful_rate >= 0.5) %>%
head()
# Extract published notes with low ratings
notes_merged %>%
filter(ratings < 6, current_status != "NEEDS_MORE_RATINGS", helpful_rate >= 0.5) %>%
head(,10)
# Extract published notes with low ratings
notes_merged %>%
filter(ratings < 6, current_status != "NEEDS_MORE_RATINGS", helpful_rate >= 0.5) %>%
tai()
# Extract published notes with low ratings
notes_merged %>%
filter(ratings < 6, current_status != "NEEDS_MORE_RATINGS", helpful_rate >= 0.5) %>%
tail()
# Extract published notes with low ratings
notes_merged %>%
filter(ratings < 6, current_status != "NEEDS_MORE_RATINGS", helpful_rate >= 0.75) %>%
tail()
# Extract published notes with low ratings
notes_merged %>%
filter(ratings < 6, current_status != "NEEDS_MORE_RATINGS", helpful_rate >= 0.75) %>%
View()
# Extract published notes with low ratings
notes_merged %>%
filter(ratings < 6, current_status != "NEEDS_MORE_RATINGS", helpful_rate >= 0.75) %>%
head()
# Extract published notes with low ratings
notes_merged %>%
filter(ratings < 6, current_status != "NEEDS_MORE_RATINGS", helpful_rate >= 0.75) %>%
head()
# packages and data ----
library(pacman)
id_snippet <- notes_merged %>% select(tweet_id)
# packages and data ----
library(pacman)
p_load(tidyverse,
ggplot2,
corrplot)
id_snippet <- notes_merged %>% select(tweet_id)
View(id_snippet)
id_snippet <- notes_merged %>% select(tweet_id) %>% head(100)
View(id_snippet)
snippet_list <- paste0('"',id_snippet$tweet_id,'"', collapse = ",")
snippet_list <- paste0("[",snippet_listm"]")
snippet_list <- paste0("[",snippet_listm,"]")
snippet_list <- paste0("[",snippet_list,"]")
write(snippet_list, file = "tweet_ids.txt")
# Grab 100 ids to use in python
id_snippet <- notes_merged %>% select(tweet_id) %>% head(100)
View(id_snippet)
snippet_list <- paste0("[", paste(id_snippet$tweet_ids, collapse = ", "), "]")
snippet_list <- paste0("[", paste(id_snippet$tweet_id, collapse = ", "), "]")
write(snippet_list, file = "tweet_ids.txt")
snippet_list <- paste0("[", paste(id_snippet$tweet_id, collapse = ","), "]")
write(snippet_list, file = "tweet_ids.txt")
View(id_snippet)
# Grab 100 ids to use in python
id_snippet <- notes_merged %>% select(tweet_id) %>% head(50)
# packages and data ----
library(pacman)
p_load(tidyverse,
ggplot2,
corrplot)
# Grab 100 ids to use in python
id_snippet <- notes_merged %>% select(tweet_id) %>% head(50)
View(id_snippet)
# Grab 100 ids to use in python
id_snippet <- notes_merged %>% select(tweet_id) %>% tail(50)
View(id_snippet)
snippet_list <- paste0("[", paste(id_snippet$tweet_id, collapse = ","), "]")
write(snippet_list, file = "tweet_ids.txt")
# Grab 100 ids to use in python
id_snippet <- notes_merged %>% select(tweet_id) %>% head(100)
View(id_snippet)
snippet_list <- paste0("[", paste(id_snippet$tweet_id, collapse = ","), "]")
write(snippet_list, file = "tweet_ids.txt")
load("data/notes_merged.RData")
# Grab 100 ids to use in python
id_snippet <- notes_merged %>% select(tweet_id) %>% head(100)
# packages and data ----
library(pacman)
p_load(tidyverse,
ggplot2,
corrplot)
# Nate EDA ----
# Remove scientific notation/filter for tweets with ratings
notes_merged$tweet_id <- notes_merged$tweet_id %>% format(scientific = F)
notes_merged <- notes_merged %>% filter(ratings>0)
# Look at number of ratings to get a note published
notes_merged %>% group_by(current_status) %>%
summarise(quantile(ratings,probs = 0.25))
# Extract published notes with low ratings
notes_merged %>%
filter(ratings < 6, current_status != "NEEDS_MORE_RATINGS", helpful_rate >= 0.75) %>%
View()
# Grab 100 ids to use in python
id_snippet <- notes_merged %>% select(tweet_id) %>% head(100)
View(id_snippet)
snippet_list <- paste0("[", paste(id_snippet$tweet_id, collapse = ","), "]")
write(snippet_list, file = "tweet_ids.txt")
